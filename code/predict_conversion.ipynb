{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the conversion MCI -> AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skrebate import ReliefF\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from mrmr import mrmr_classif\n",
    "from ITMO_FS.filters.multivariate import CMIM\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSCanonical\n",
    "#import FSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(5000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"ensemble_prediction.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>sexo</th>\n",
       "      <th>CSFdatatTau</th>\n",
       "      <th>CSFdatapTau</th>\n",
       "      <th>CSFdataabeta42</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>NRP2</th>\n",
       "      <th>APOA1</th>\n",
       "      <th>FETUA</th>\n",
       "      <th>...</th>\n",
       "      <th>B4GA1</th>\n",
       "      <th>KV127</th>\n",
       "      <th>NAR3</th>\n",
       "      <th>MYO6</th>\n",
       "      <th>MANBA</th>\n",
       "      <th>SODM</th>\n",
       "      <th>FIBG</th>\n",
       "      <th>CNTP4</th>\n",
       "      <th>HV349</th>\n",
       "      <th>A2AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>95</td>\n",
       "      <td>552</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>9.050000e-06</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>563</td>\n",
       "      <td>77</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00434</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>1.460000e-06</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1201</td>\n",
       "      <td>135</td>\n",
       "      <td>399</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>6.540000e-06</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>104</td>\n",
       "      <td>389</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.00514</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>2.540000e-05</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.00230</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>26</td>\n",
       "      <td>324</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.00313</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>7.520000e-07</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>74</td>\n",
       "      <td>504</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>3.090000e-06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>404</td>\n",
       "      <td>68</td>\n",
       "      <td>855</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.00487</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00229</td>\n",
       "      <td>9.840000e-06</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>770</td>\n",
       "      <td>103</td>\n",
       "      <td>540</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>1.400000e-06</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>110</td>\n",
       "      <td>475</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00443</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>1.010000e-05</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.00235</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>86</td>\n",
       "      <td>558</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>8.910000e-06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.00231</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>892</td>\n",
       "      <td>117</td>\n",
       "      <td>512</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>1.960000e-05</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>767</td>\n",
       "      <td>100</td>\n",
       "      <td>513</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>2.780000e-06</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1830</td>\n",
       "      <td>165</td>\n",
       "      <td>440</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.00361</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>8.910000e-06</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>767</td>\n",
       "      <td>73</td>\n",
       "      <td>389</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.00359</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>1.810000e-05</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>61</td>\n",
       "      <td>473</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00287</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>4.580000e-06</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.00209</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "      <td>91</td>\n",
       "      <td>580</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>1.140000e-05</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>43</td>\n",
       "      <td>587</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.00216</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>2.620000e-06</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>35</td>\n",
       "      <td>406</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>4.040000e-06</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1150</td>\n",
       "      <td>123</td>\n",
       "      <td>421</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00294</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00342</td>\n",
       "      <td>2.380000e-06</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>65</td>\n",
       "      <td>487</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>2.480000e-05</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1850</td>\n",
       "      <td>133</td>\n",
       "      <td>381</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00444</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00379</td>\n",
       "      <td>3.270000e-06</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>576</td>\n",
       "      <td>60</td>\n",
       "      <td>571</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.00359</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>9.910000e-06</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>70</td>\n",
       "      <td>555</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>2.460000e-05</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>603</td>\n",
       "      <td>63</td>\n",
       "      <td>560</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00480</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>3.300000e-06</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.00252</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.001490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1360</td>\n",
       "      <td>118</td>\n",
       "      <td>609</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.00575</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>4.240000e-06</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "      <td>111</td>\n",
       "      <td>479</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>1.360000e-05</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>75</td>\n",
       "      <td>525</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00294</td>\n",
       "      <td>2.100000e-05</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00326</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>498</td>\n",
       "      <td>66</td>\n",
       "      <td>465</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.00602</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>1.900000e-05</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.00229</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1790</td>\n",
       "      <td>136</td>\n",
       "      <td>652</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.00443</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00304</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.00360</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>44</td>\n",
       "      <td>375</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>5.790000e-06</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "      <td>98</td>\n",
       "      <td>580</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00315</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>1.440000e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "      <td>140</td>\n",
       "      <td>450</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>2.400000e-05</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "      <td>75</td>\n",
       "      <td>555</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00286</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>8.890000e-06</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00457</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>59</td>\n",
       "      <td>494</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00363</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>7.700000e-06</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>30</td>\n",
       "      <td>463</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.00383</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>1.310000e-05</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>929</td>\n",
       "      <td>108</td>\n",
       "      <td>596</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.00314</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>3.440000e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    idade  sexo  CSFdatatTau  CSFdatapTau  CSFdataabeta42  MMSE  Cluster  \\\n",
       "0      76     1          618           95             552    27        0   \n",
       "1      77     0          563           77             349    30        1   \n",
       "2      72     0         1201          135             399    22        0   \n",
       "3      61     1          680          104             389    26        1   \n",
       "4      63     1          200           26             324    22        1   \n",
       "5      59     1          540           74             504    24        0   \n",
       "6      74     1          404           68             855    23        1   \n",
       "7      73     0          770          103             540    23        1   \n",
       "8      61     1         1080          110             475    25        1   \n",
       "9      71     0          702           86             558    26        0   \n",
       "10     67     1          892          117             512    21        0   \n",
       "11     66     1          767          100             513    25        0   \n",
       "12     67     1         1830          165             440    21        0   \n",
       "13     68     1          767           73             389    26        1   \n",
       "14     65     1          520           61             473    25        1   \n",
       "15     71     0          869           91             580    26        0   \n",
       "16     70     0          329           43             587    25        0   \n",
       "17     66     1          333           35             406    27        1   \n",
       "18     67     1         1150          123             421    21        0   \n",
       "19     73     0          519           65             487    25        1   \n",
       "20     68     1         1850          133             381    30        0   \n",
       "21     59     1          576           60             571    24        1   \n",
       "22     65     0          606           70             555    28        1   \n",
       "23     62     1          603           63             560    24        0   \n",
       "24     77     1         1360          118             609    24        0   \n",
       "25     72     1         1130          111             479    22        0   \n",
       "26     79     1          594           75             525    26        0   \n",
       "27     75     1          498           66             465    25        0   \n",
       "28     65     1         1790          136             652    25        0   \n",
       "29     71     0          277           44             375    28        0   \n",
       "30     69     1          749           98             580    25        0   \n",
       "31     58     0         1100          140             450    28        1   \n",
       "32     74     1          566           75             555    27        1   \n",
       "33     71     0          539           59             494    24        1   \n",
       "34     73     0          186           30             463    26        1   \n",
       "35     64     1          929          108             596    25        1   \n",
       "\n",
       "        NRP2    APOA1     FETUA  ...    B4GA1         KV127      NAR3  \\\n",
       "0   0.000155  0.00331  0.000652  ...  0.00184  9.050000e-06  0.000070   \n",
       "1   0.000020  0.00434  0.000902  ...  0.00201  1.460000e-06  0.000161   \n",
       "2   0.000031  0.00223  0.000419  ...  0.00258  6.540000e-06  0.000165   \n",
       "3   0.000145  0.00514  0.001170  ...  0.00202  2.540000e-05  0.000173   \n",
       "4   0.000012  0.00313  0.000769  ...  0.00154  7.520000e-07  0.000116   \n",
       "5   0.000032  0.00370  0.000844  ...  0.00223  3.090000e-06  0.000169   \n",
       "6   0.000019  0.00487  0.001050  ...  0.00229  9.840000e-06  0.000239   \n",
       "7   0.000020  0.00445  0.001070  ...  0.00146  1.400000e-06  0.000107   \n",
       "8   0.000013  0.00443  0.000885  ...  0.00125  1.010000e-05  0.000091   \n",
       "9   0.000013  0.00451  0.000796  ...  0.00193  8.910000e-06  0.000169   \n",
       "10  0.000158  0.00558  0.000906  ...  0.00390  1.960000e-05  0.000188   \n",
       "11  0.000033  0.00269  0.000199  ...  0.00369  2.780000e-06  0.000184   \n",
       "12  0.000173  0.00361  0.000736  ...  0.00282  8.910000e-06  0.000179   \n",
       "13  0.000016  0.00359  0.000221  ...  0.00196  1.810000e-05  0.000112   \n",
       "14  0.000025  0.00287  0.000941  ...  0.00246  4.580000e-06  0.000116   \n",
       "15  0.000017  0.00338  0.000649  ...  0.00274  1.140000e-05  0.000184   \n",
       "16  0.000012  0.00216  0.000796  ...  0.00238  2.620000e-06  0.000091   \n",
       "17  0.000090  0.00372  0.000943  ...  0.00132  4.040000e-06  0.000116   \n",
       "18  0.000013  0.00294  0.000513  ...  0.00342  2.380000e-06  0.000197   \n",
       "19  0.000098  0.00456  0.001310  ...  0.00196  2.480000e-05  0.000252   \n",
       "20  0.000025  0.00444  0.000747  ...  0.00379  3.270000e-06  0.000168   \n",
       "21  0.000070  0.00359  0.000982  ...  0.00155  9.910000e-06  0.000148   \n",
       "22  0.000015  0.00590  0.001050  ...  0.00192  2.460000e-05  0.000209   \n",
       "23  0.000008  0.00480  0.000946  ...  0.00338  3.300000e-06  0.000149   \n",
       "24  0.000028  0.00575  0.000901  ...  0.00330  4.240000e-06  0.000164   \n",
       "25  0.000227  0.00428  0.000746  ...  0.00240  1.360000e-05  0.000088   \n",
       "26  0.000170  0.00525  0.000811  ...  0.00294  2.100000e-05  0.000131   \n",
       "27  0.000162  0.00602  0.000707  ...  0.00272  1.900000e-05  0.000136   \n",
       "28  0.000198  0.00443  0.000810  ...  0.00304  5.500000e-06  0.000226   \n",
       "29  0.000293  0.00611  0.001460  ...  0.00206  5.790000e-06  0.000303   \n",
       "30  0.000067  0.00315  0.000607  ...  0.00227  1.440000e-06  0.000104   \n",
       "31  0.000015  0.00461  0.000810  ...  0.00192  2.400000e-05  0.000087   \n",
       "32  0.000025  0.00286  0.000854  ...  0.00323  8.890000e-06  0.000135   \n",
       "33  0.000031  0.00363  0.000716  ...  0.00168  7.700000e-06  0.000146   \n",
       "34  0.000063  0.00383  0.000839  ...  0.00150  1.310000e-05  0.000169   \n",
       "35  0.000006  0.00314  0.000128  ...  0.00247  3.440000e-06  0.000104   \n",
       "\n",
       "        MYO6     MANBA      SODM     FIBG     CNTP4     HV349      A2AP  \n",
       "0   0.000059  0.000210  0.000079  0.00122  0.000135  0.000127  0.000954  \n",
       "1   0.000034  0.001250  0.000043  0.00257  0.000411  0.000096  0.000550  \n",
       "2   0.000037  0.000333  0.000297  0.00173  0.000242  0.000077  0.000539  \n",
       "3   0.000049  0.001120  0.000084  0.00230  0.000868  0.000151  0.000663  \n",
       "4   0.000372  0.000826  0.000284  0.00124  0.000973  0.000117  0.000697  \n",
       "5   0.000052  0.000279  0.000098  0.00143  0.000432  0.000141  0.000695  \n",
       "6   0.000029  0.000466  0.000074  0.00277  0.000298  0.000100  0.001120  \n",
       "7   0.000049  0.000207  0.000076  0.00243  0.000317  0.000160  0.001130  \n",
       "8   0.000029  0.000761  0.000053  0.00235  0.000205  0.000158  0.000899  \n",
       "9   0.000038  0.000262  0.000070  0.00231  0.000928  0.000099  0.000514  \n",
       "10  0.000093  0.000171  0.000124  0.00268  0.000364  0.000115  0.000818  \n",
       "11  0.000046  0.000812  0.000076  0.00192  0.000320  0.000019  0.000901  \n",
       "12  0.000077  0.000172  0.000096  0.00267  0.000344  0.000160  0.000484  \n",
       "13  0.000029  0.001000  0.000092  0.00214  0.000179  0.000074  0.001030  \n",
       "14  0.000420  0.000419  0.000081  0.00209  0.000407  0.000106  0.001410  \n",
       "15  0.000048  0.000406  0.000066  0.00174  0.000249  0.000107  0.000608  \n",
       "16  0.000034  0.000237  0.000286  0.00167  0.000963  0.000126  0.000998  \n",
       "17  0.000272  0.000427  0.000125  0.00202  0.000530  0.000107  0.001140  \n",
       "18  0.000041  0.001320  0.000107  0.00154  0.000217  0.000051  0.000775  \n",
       "19  0.000022  0.000679  0.000025  0.00261  0.000964  0.000146  0.000694  \n",
       "20  0.000043  0.000791  0.000088  0.00248  0.000328  0.000100  0.000547  \n",
       "21  0.000267  0.000466  0.000279  0.00186  0.000280  0.000120  0.000639  \n",
       "22  0.000028  0.001190  0.000093  0.00295  0.000292  0.000257  0.001140  \n",
       "23  0.000035  0.001430  0.000086  0.00252  0.000398  0.000096  0.001490  \n",
       "24  0.000352  0.000521  0.000113  0.00281  0.000216  0.000122  0.000892  \n",
       "25  0.000028  0.000398  0.000020  0.00263  0.000221  0.000087  0.000504  \n",
       "26  0.000028  0.000213  0.000067  0.00326  0.000223  0.000135  0.000933  \n",
       "27  0.000027  0.000892  0.000262  0.00229  0.000178  0.000041  0.000470  \n",
       "28  0.000040  0.000476  0.000119  0.00360  0.000303  0.000085  0.000404  \n",
       "29  0.000063  0.000361  0.000214  0.00239  0.000273  0.000131  0.000883  \n",
       "30  0.000020  0.000828  0.000169  0.00154  0.000125  0.000045  0.000949  \n",
       "31  0.000021  0.000487  0.000036  0.00238  0.000183  0.000166  0.000978  \n",
       "32  0.000473  0.000508  0.000031  0.00457  0.000250  0.000141  0.001140  \n",
       "33  0.000019  0.000987  0.000016  0.00269  0.000246  0.000093  0.001050  \n",
       "34  0.000406  0.000756  0.000234  0.00372  0.001020  0.000117  0.001230  \n",
       "35  0.000339  0.000424  0.000083  0.00268  0.000411  0.000111  0.000385  \n",
       "\n",
       "[36 rows x 171 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = 5\n",
    "dir ='lisbon'\n",
    "df = pd.read_csv('../data/'+dir+'/conversion_ad/{}tw_no_norm.csv'.format(tw))\n",
    "all_features = df.copy()\n",
    "y = df['Evolution'].copy()\n",
    "all_features.drop(columns = ['Code','Group', 'BBA', 'CSFdate', 'comentarios', 'Conversion', 'data', 'tempofollowup', 'Evolution'], inplace = True) # drop unwanted columns\n",
    "all_features['sexo'].replace({'M' : 0, 'F': 1}, inplace = True)\n",
    "numerical_features = [feature for feature in all_features.columns if feature not in ['sexo', 'Cluster']]\n",
    "#normalize non normalized columns: idade, CSFdatatTau, CSFdatapTau, CSFdataabeta42, MMSE\n",
    "#non_normalized_columns = ['idade', 'CSFdatatTau', 'CSFdatapTau', 'CSFdataabeta42', 'MMSE']\n",
    "#all_features[non_normalized_columns] = (all_features[non_normalized_columns] -all_features[non_normalized_columns].min())/(all_features[non_normalized_columns].max() - all_features[non_normalized_columns].min())\n",
    "all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection ensemble** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FS methods: ReliefF, MIM, CMIM, MRMR, Chi-Squared, LL21 (do not understand the implementation, used rf as the embedded method instead)\n",
    "SVM-RFE excluded (see telma's paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FS_ensemble(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fs_ensemble(self,x_train, y_train):\n",
    "        # get rankings of each fs method\n",
    "        print('FS')\n",
    "        #relieff\n",
    "        #reliefFS = ReliefF(n_neighbors = 2, n_features_to_select = len(x_train.columns)) #n_features_to_keep = len(x_train.columns)\n",
    "        #reliefFS.fit(x_train.values, y_train)\n",
    "        #relief_rank = np.argsort(np.argsort(-reliefFS.feature_importances_)) # rank of the features according to it importance: the higher the importance the lower the rank\n",
    "\n",
    "        # mim\n",
    "        mutual_info = mutual_info_classif(x_train, y_train, random_state = 42)\n",
    "        mutual_info_rank = np.argsort(np.argsort(-mutual_info))\n",
    "\n",
    "        # cmim\n",
    "        #cmimFS = CMIM(np.empty(0), np.array(x_train.columns), X = x_train.values, y = y_train)\n",
    "        #cmim_rank = np.argsort(np.argsort(-cmimFS))\n",
    "\n",
    "        #mrmr\n",
    "        #mrmrFS = mrmr_classif(X=x_train, y=y_train, K=len(x_train.columns), n_jobs = -1, show_progress = False)\n",
    "        #mrmrFS_rank = [mrmrFS.index(item) for item in x_train.columns]\n",
    "\n",
    "        # chi-squared\n",
    "        #chi2_filter = chi2(x_train.values,y_train)\n",
    "        #chi2_rank = np.argsort(np.argsort(-chi2_filter[0]))\n",
    "\n",
    "        #anova\n",
    "        f_values, p_values = f_classif(x_train.values, y_train)\n",
    "        f_rank = np.argsort(np.argsort(-f_values))\n",
    "\n",
    "        #VIF\n",
    "        #vif = [variance_inflation_factor(x_train.values, i) for i in range(len(x_train.columns))]\n",
    "        #vif_rank = np.argsort(np.argsort(vif))\n",
    "\n",
    "        #LL21\n",
    "        #selection = SelectFromModel(LogisticRegression(solver = 'liblinear', penalty='l1'))\n",
    "        #selection.fit(x_train.values, y_train)\n",
    "        #ll21_rank = x_train.columns[(selection.get_support())]\n",
    "        #print(ll21_rank)\n",
    "        lr = LogisticRegression(penalty='l1', solver='liblinear', random_state = 42)#, l1_ratio=0.5, max_iter=10000, dual = True)\n",
    "        lr.fit(x_train, y_train)\n",
    "        lr_importances = np.absolute(lr.coef_[0])\n",
    "        lr_rank = np.argsort(np.argsort(-lr_importances))\n",
    "        # Assign the rank len(X.columns) to the zero coefficients\n",
    "\n",
    "\n",
    "        # permutation importance rf\n",
    "        rf = RandomForestClassifier(n_estimators=100, max_features = None, random_state=42)\n",
    "        rf.fit(x_train, y_train)\n",
    "        #rf_importances = permutation_importance(rf, x_train, y_train, n_repeats=4, random_state=42, n_jobs=-1)\n",
    "        #rf_importances_mean = rf_importances.importances_mean\n",
    "        rf_importances = rf.feature_importances_\n",
    "        rf_rank = np.argsort(np.argsort(-rf_importances))\n",
    "\n",
    "        # SHAP\n",
    "        explainer = shap.TreeExplainer(rf)\n",
    "        # Calculate SHAP values for the train set\n",
    "        shap_values_train = explainer.shap_values(x_train)\n",
    "        #print(len(shap_values_train))\n",
    "        # Mean absolute SHAP values to determine global feature importance\n",
    "        #shap_importance_train = np.abs(shap_values_train).mean(0)\n",
    "        shap_importance_train = np.mean([np.abs(val).mean(0) for val in shap_values_train], axis=0)\n",
    "        #print(shap_importance_train.shape)\n",
    "        shap_rank = np.argsort(np.argsort(-shap_importance_train))\n",
    "        #print(len(shap_rank))\n",
    "        #xgb\n",
    "        #xgb = XGBClassifier(random_state = 42)\n",
    "        #xgb.fit(x_train, y_train)\n",
    "        #xgb_importances = xgb.feature_importances_\n",
    "        #xgb_rank = np.argsort(np.argsort(-xgb_importances))\n",
    "\n",
    "        #Rank aggregator: get a final subset in which the rank is the mean of all subsets\n",
    "        #res = [sum(values) /6 for values in zip(mutual_info_rank + chi2_rank + f_rank+ lr_rank + rf_rank + xgb_rank)] #average position\n",
    "        res = [sum(values) / len(values) for values in zip(mutual_info_rank, f_rank, lr_rank, rf_rank, shap_rank)]\n",
    "        ranked_features = dict(zip(x_train.columns, res))\n",
    "        #print(ranked_features['idade'])\n",
    "        ranked_features = list(dict(sorted(ranked_features.items(), key=lambda item: item[1])).keys())\n",
    "        #print(ranked_features)\n",
    "        return ranked_features[:self.k]\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Apply the feature selection function to the training data\n",
    "        self.selected_features_ = self.fs_ensemble(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Select features based on the result from feature_selector_func\n",
    "        return X.loc[:, self.selected_features_]\n",
    "    \n",
    "    def get_features(self):\n",
    "        return self.selected_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to return DataFrame after MinMax scaling\n",
    "class DataFrameMinMaxScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = X.columns\n",
    "        self.scaler.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.columns = X.columns\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        # Convert back to DataFrame, keeping original column names\n",
    "        return pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        return pd.DataFrame(X_scaled, columns=self.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicSMOTENC(BaseEstimator):\n",
    "    def __init__(self, sampling_strategy=0.95, random_state=42):\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.random_state = random_state\n",
    "        self.smote = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Identify categorical feature indices\n",
    "        self.cat_indices = [i for i, column in enumerate(X.columns) if column in ['sexo', 'Cluster']]\n",
    "    \n",
    "        # Choose SMOTENC if there are categorical features, otherwise SMOTE\n",
    "        if self.cat_indices:\n",
    "            self.smote = SMOTENC(categorical_features=self.cat_indices, categorical_encoder = OneHotEncoder(sparse_output = False),\n",
    "                                 sampling_strategy=self.sampling_strategy, k_neighbors=3,\n",
    "                                 random_state=self.random_state)\n",
    "            #self.smote.ohe_.set_params({'sparse_output': False})\n",
    "        else:\n",
    "            self.smote = SMOTE(sampling_strategy=self.sampling_strategy, k_neighbors=3,\n",
    "                               random_state=self.random_state)\n",
    "        \n",
    "        # Fit the SMOTE/SMOTENC with X and y\n",
    "        self.smote.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def fit_resample(self, X, y=None):\n",
    "        self.cat_indices = [i for i, column in enumerate(X.columns) if column in ['sexo', 'Cluster']]\n",
    "    \n",
    "        # Choose SMOTENC if there are categorical features, otherwise SMOTE\n",
    "        if self.cat_indices:\n",
    "            self.smote = SMOTENC(categorical_features=self.cat_indices, categorical_encoder = OneHotEncoder(sparse_output = False),\n",
    "                                 sampling_strategy=self.sampling_strategy, k_neighbors=3,\n",
    "                                 random_state=self.random_state)\n",
    "            #self.smote.ohe_.set_params({'sparse_output': False})\n",
    "\n",
    "        else:\n",
    "            self.smote = SMOTE(sampling_strategy=self.sampling_strategy, k_neighbors=3,\n",
    "                               random_state=self.random_state)\n",
    "\n",
    "        # Apply SMOTE/SMOTENC\n",
    "        X_res, y_res = self.smote.fit_resample(X, y)\n",
    "        #X_res = pd.DataFrame(X_res, columns=X.columns)\n",
    "        return X_res, y_res\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10x5 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers to evaluate\n",
    "# Define classifiers and their parameter grids\n",
    "classifiers = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(solver='liblinear'),\n",
    "        'params': {\n",
    "            'classification__C': [0.1, 0.5, 1, 5, 10],\n",
    "            'classification__class_weight' : [None, 'balanced'],\n",
    "            'classification__penalty': ['l1', 'l2'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'classification__n_estimators': [10,50, 100, 200],\n",
    "            'classification__max_depth': [None, 10, 15,20,25],\n",
    "            'classification__class_weight' : [None, 'balanced'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'XGBgClassifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'classification__n_estimators': [10, 50, 100,300],\n",
    "            'classification__max_depth': [5,10,15,20],\n",
    "            'classification__learning_rate': [0.0001, 0.001, 0.01],\n",
    "            'classification__objective': ['binary:logistic'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'classification__C': [0.1, 0.5, 1, 10],\n",
    "            'classification__kernel': ['linear','poly','rbf', 'sigmoid'],\n",
    "            'classification__probability': [True],\n",
    "            'classification__class_weight' : [None, 'balanced'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'NB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {'classification__var_smoothing' : [10**-9, 10**-8, 10**-10]}\n",
    "    },\n",
    "    'DTClassifier': {\n",
    "    'model': tree.DecisionTreeClassifier(),\n",
    "    'params': {'classification__max_depth': [None, 10, 20],\n",
    "              'classification__class_weight' : [None, 'balanced'],\n",
    "              'classification__random_state' : [42]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "\n",
    "def sens(y_true, y_pred): return tp(y_true, y_pred) / \\\n",
    "    (fn(y_true, y_pred) + tp(y_true, y_pred))\n",
    "\n",
    "\n",
    "def spec(y_true, y_pred): return tn(y_true, y_pred) / \\\n",
    "    (fp(y_true, y_pred) + tn(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_scorer = make_scorer(sens)\n",
    "\n",
    "# Specificity scorer\n",
    "specificity_scorer = make_scorer(spec)\n",
    "\n",
    "# AUC scorer\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "# accuracy scorer\n",
    "accuracy_scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple example\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features, y, test_size=0.33, random_state=42)\n",
    "for k in range(1,len(all_features.columns)):\n",
    "    print(k)\n",
    "    selected = FS_ensemble(k = k)\n",
    "    selected.fit(X_train,y_train)\n",
    "    train_data = selected.transform(X_train)\n",
    "    clf = LogisticRegression(random_state=0).fit(train_data, y_train)\n",
    "    test_data = selected.transform(X_test)\n",
    "    clf.predict(test_data)\n",
    "    print(clf.score(test_data, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.77\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.655\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7533333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.58\n",
      "3\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.8133333333333332\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.5933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.6366666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.78\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666666\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.6\n",
      "4\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.63\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.7\n",
      "5\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.635\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7133333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "6\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.5933333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6133333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5666666666666667\n",
      "7\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6799999999999999\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.5916666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.5533333333333333\n",
      "SVC\n",
      "FS\n",
      "auc:  0.6566666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6133333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5666666666666667\n",
      "8\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6866666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.54\n",
      "SVC\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.55\n",
      "9\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7566666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.5133333333333334\n",
      "SVC\n",
      "FS\n",
      "auc:  0.77\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666666\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5166666666666666\n",
      "10\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6799999999999999\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6966666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "SVC\n",
      "FS\n",
      "auc:  0.72\n",
      "NB\n",
      "FS\n",
      "auc:  0.7333333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.6\n",
      "11\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.72\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5166666666666667\n",
      "12\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7366666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.75\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.52\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5466666666666666\n",
      "13\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7366666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.755\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.5133333333333334\n",
      "SVC\n",
      "FS\n",
      "auc:  0.74\n",
      "NB\n",
      "FS\n",
      "auc:  0.7133333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5333333333333334\n",
      "14\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.4133333333333333\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7\n",
      "NB\n",
      "FS\n",
      "auc:  0.6466666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5633333333333334\n",
      "15\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32000000000000006\n",
      "SVC\n",
      "FS\n",
      "auc:  0.71\n",
      "NB\n",
      "FS\n",
      "auc:  0.6466666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5466666666666666\n",
      "16\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6866666666666668\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.665\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.63\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "17\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7299999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.63\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666666\n",
      "18\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33666666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6799999999999999\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "19\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.76\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7350000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "SVC\n",
      "FS\n",
      "auc:  0.78\n",
      "NB\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "20\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.76\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6366666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.46333333333333326\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.48\n",
      "21\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.4466666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "22\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7933333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7566666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.7100000000000001\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "23\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7700000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "24\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6649999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.3433333333333334\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.55\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.46333333333333326\n",
      "25\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.64\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.3166666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.56\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.46333333333333326\n",
      "26\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7933333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6566666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "27\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6533333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2966666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7933333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "28\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.3\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "29\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27666666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7566666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6566666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "30\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.645\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.30666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.74\n",
      "NB\n",
      "FS\n",
      "auc:  0.6900000000000001\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "31\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.65\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.30666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6966666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "32\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.29\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "33\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7566666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.44000000000000006\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "34\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "35\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7516666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.44000000000000006\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.7000000000000001\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5466666666666666\n",
      "36\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7966666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6849999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.7333333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.48\n",
      "37\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7966666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.75\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "38\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.66\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.75\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "39\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31333333333333335\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4800000000000001\n",
      "40\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2833333333333333\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "41\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.30000000000000004\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6666666666666666\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "42\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2666666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "43\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2666666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "44\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.72\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.26666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "45\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7300000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.30000000000000004\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "46\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.73\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2966666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "47\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7333333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2966666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.48\n",
      "48\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2966666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "49\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6799999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "50\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "51\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6966666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.65\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "52\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4800000000000001\n",
      "53\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6066666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "54\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6566666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7016666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "55\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7666666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "56\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6566666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7066666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36333333333333334\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7666666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333334\n",
      "57\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7283333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7666666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "58\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36333333333333334\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "59\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.64\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7016666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36333333333333334\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.5333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4966666666666667\n",
      "60\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6566666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.44333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.5166666666666666\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "61\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.73\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.5666666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "62\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6966666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.5666666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "63\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.5666666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "64\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.2966666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.5666666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.46333333333333326\n",
      "65\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.65\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7666666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.5833333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.46333333333333326\n",
      "66\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.44333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "67\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7133333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.44333333333333336\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "68\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6900000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "69\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "70\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7083333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "71\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.735\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "72\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6683333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.27999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7333333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333334\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "73\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.65\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.71\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "74\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.825\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.45999999999999996\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7666666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333334\n",
      "75\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.76\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.45999999999999996\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6166666666666667\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333333\n",
      "76\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6833333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.45999999999999996\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.53\n",
      "77\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7016666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.45999999999999996\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.46333333333333326\n",
      "78\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "79\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7166666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "80\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333334\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "81\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.74\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7666666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "82\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6916666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7633333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "83\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6666666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.8016666666666665\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.76\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "84\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.67\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7416666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "85\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.67\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6666666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "86\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6366666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.3966666666666667\n",
      "87\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7016666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "88\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "89\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "90\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.75\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "91\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6399999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "92\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7916666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "93\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6366666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8083333333333332\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.3966666666666667\n",
      "94\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6066666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8083333333333332\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "95\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.62\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6966666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8083333333333332\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "96\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.73\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33999999999999997\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8083333333333332\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "97\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.705\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "98\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8333333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "99\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6366666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6816666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "100\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6633333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "101\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "102\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7216666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "103\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6100000000000001\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6333333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8333333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "104\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "105\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7183333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8333333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "106\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6066666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7200000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "107\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6333333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "108\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7133333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7133333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.33666666666666667\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "109\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6433333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8166666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "110\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8166666666666667\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "111\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6233333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7100000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.4666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "112\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6866666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "113\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7133333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8333333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "114\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6533333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.725\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8333333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "115\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.71\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "116\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.32666666666666666\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8083333333333332\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "117\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7916666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8083333333333332\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "118\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "119\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7133333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.4333333333333333\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.5133333333333334\n",
      "120\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "121\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6733333333333333\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6883333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "122\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7066666666666668\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "123\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "124\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.78\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "125\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "126\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6583333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "127\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6900000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.65\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "128\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7100000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "129\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "130\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.845\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "131\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.74\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7966666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "132\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6866666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "133\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.71\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "134\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.8216666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "135\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6649999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "136\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6183333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "137\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "138\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.71\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "139\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7133333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "140\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7283333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "141\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "142\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "143\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7766666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "144\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7233333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.76\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "145\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6683333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "146\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.36666666666666664\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "147\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6966666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "148\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7466666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "149\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6799999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "150\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.65\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "151\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7033333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.8\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.36333333333333334\n",
      "152\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.71\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6866666666666668\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "153\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.71\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7916666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "154\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.71\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7016666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7916666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "155\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.71\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7299999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7916666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43\n",
      "156\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.71\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.9099999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7916666666666666\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "157\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7766666666666666\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "158\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.76\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.36333333333333334\n",
      "159\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.76\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6599999999999999\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.4133333333333334\n",
      "160\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.76\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7066666666666667\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.36333333333333334\n",
      "161\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.76\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7333333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "162\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.43000000000000005\n",
      "163\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6766666666666666\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "164\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.71\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7133333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "165\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7383333333333333\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "166\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.745\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.38\n",
      "167\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7433333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.6933333333333332\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "168\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7300000000000001\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.44666666666666666\n",
      "169\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.7266666666666667\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.7183333333333334\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7733333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.3966666666666666\n",
      "170\n",
      "LogisticRegression\n",
      "FS\n",
      "auc:  0.6933333333333334\n",
      "RandomForestClassifier\n",
      "FS\n",
      "auc:  0.685\n",
      "XGBgClassifier\n",
      "FS\n",
      "auc:  0.31666666666666665\n",
      "SVC\n",
      "FS\n",
      "auc:  0.7833333333333333\n",
      "NB\n",
      "FS\n",
      "auc:  0.6\n",
      "DTClassifier\n",
      "FS\n",
      "auc:  0.39666666666666667\n",
      "Best Classifier: RandomForestClassifier \n",
      "Number of features: 156\n",
      "Features:['APOL1', 'NRP2', 'CIP4', 'TRFE', 'RELN', 'CLC11', 'SORL', 'APOA1', 'HPT', 'C163A', 'GRIA4', 'APLP2', 'PRELP', 'FGFR2', 'CBLN4', 'IGA2', 'PLXB2', 'TAGL', 'CNTN6', 'IBP6', 'SPON1', 'SAP', 'MMSE', 'SAA4', 'NPC2', 'ALBU', 'FRIL', 'CNTN2', 'SGCE', 'EFNB3', 'C1RL', 'CNTP4', 'EGFLA', 'MYO6', 'EPDR1', 'VGF', 'idade', 'CAHD1', 'NRX1A', 'PTPRF', 'MANBA', 'NEUS', 'RTN4R', 'A2AP', 'NAR3', 'TIMP2', 'KLKB1', 'AMBP', 'DHPR', 'KV127', 'TPP1', 'NEO1', 'CPVL', 'B4GA1', 'COMP', 'HBA', 'LFNG', 'APLP1', 'ALS', 'OMD', 'CSPG2', 'NPTXR', 'A1AG1', 'NID2', 'NCAN', 'FUCO2', 'KPYM', 'ROBO1', 'PEDF', 'FETUA', 'MA1C1', 'AEBP1', 'FGFR1', 'AFAM', 'CFAI', 'HRG', 'SAP3', 'ANT3', 'FHR1', 'PGS2', 'FUCO', 'HEMO', 'SODM', 'CADH2', 'COCA1', 'IGK', 'FBLN2', 'TTHY', 'LTBP1', 'NBL1', 'KV106', 'LDHB', 'HV349', 'ACTS', 'CBPQ', 'PEBP1', 'LV657', 'APOB', 'KV37', 'C4BPA', 'LTBP4', 'CFAB', 'FIBG', 'ITIH4', 'CSFdataabeta42', 'CO4B', 'APOA4', 'C1QA', 'RNAS4', 'COFA1', 'CO9', 'PPIC', 'DKK3', 'ICAM5', 'SLIK1', 'CNTP2', 'CERU', 'CSFdatatTau', 'PON1', 'CO6A2', 'VWF', 'H6ST3', 'GDIA', 'CBLN1', 'PTPRZ', 'A1BG', 'ITIH1', 'HV118', 'KNG1', 'C1QT3', 'HEXB', 'LV310', 'NID1', 'A1AG2', 'CSFdatapTau', 'PCDC2', 'sexo', 'C1QT1', 'SLIK4', 'FSTL5', 'SPRL1', 'A2GL', 'ICOSL', 'CO6', 'ZA2G', 'HBB', 'LV39', 'Cluster', 'CBPB2', 'ENDD1', 'DCC', 'KCC2A', 'C1QC', 'CBG', 'MDHC', 'ACYP2']\n",
      "Best Params: {'classification__class_weight': None, 'classification__max_depth': None, 'classification__n_estimators': 10, 'classification__random_state': 42}\n",
      "Best AUC: 0.9100\n",
      "Best Sens: 0.8667\n",
      "Best Spec: 0.7000\n",
      "Best Accuracy: 0.8071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the cross-validation procedure (5-fold cross-validation with 10 repetitions)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "all_scores = []\n",
    "k_scores = []\n",
    "# List to store results\n",
    "results = []\n",
    "#print(all_features)\n",
    "set_config(transform_output=\"pandas\")\n",
    "# Define the ColumnTransformer to apply MinMaxScaler only to numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),  # Custom scaler for numerical features\n",
    "        ('cat', 'passthrough', ['sexo', 'Cluster'])            # Pass categorical columns unchanged\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False, sparse_threshold=0)     #remainder='passthrough'  # Ensure other columns are passed through if not specified\n",
    "\n",
    "for k in range(2,len(all_features.columns)):   \n",
    "    #fs_ensemble = FS_ensemble(k = k) #select subset of features\n",
    "    #k = 92\n",
    "    print(k)\n",
    "    for name, clf in classifiers.items():\n",
    "        print(name)\n",
    "        pipeline = ImbPipeline([('scaler', preprocessor),\n",
    "                                ('feature_selection', FS_ensemble(k = k)), ('SMOTE', DynamicSMOTENC(sampling_strategy=0.8, random_state = 42)),\n",
    "                                #('pca', PCA()),\n",
    "                                ('classification', clf['model'])])\n",
    "        \n",
    "        #clf['params']['pca__n_components'] = list(range(2, min(k+1, len(all_features)), 5))\n",
    "        \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(pipeline, clf['params'], cv=cv, scoring={'AUC': auc_scorer, 'Sensitivity': sensitivity_scorer, 'Specificity': specificity_scorer, 'Accuracy': accuracy_scorer}, refit = 'AUC', n_jobs=-1)\n",
    "        grid_search.fit(all_features, y)\n",
    "        \n",
    "        # Get the index of the best model (based on AUC score)\n",
    "        best_index = grid_search.best_index_\n",
    "         # Extract the sensitivity and specificity for the best model\n",
    "        best_sensitivity = grid_search.cv_results_['mean_test_Sensitivity'][best_index]\n",
    "        best_std_sensitivity = grid_search.cv_results_['std_test_Sensitivity'][best_index]\n",
    "        best_specificity = grid_search.cv_results_['mean_test_Specificity'][best_index]\n",
    "        best_std_specificity = grid_search.cv_results_['std_test_Specificity'][best_index]\n",
    "        best_accuracy = grid_search.cv_results_['mean_test_Accuracy'][best_index]\n",
    "        best_std_accuracy = grid_search.cv_results_['std_test_Accuracy'][best_index]\n",
    "        # Get the best estimator (pipeline) from the grid search\n",
    "        best_model = grid_search.best_estimator_\n",
    "        # Get the selected features from the best feature selection step\n",
    "        selected_features = best_model.named_steps['feature_selection']\n",
    "        selected_features = selected_features.get_features()\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "        'classifier': name,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_auc': grid_search.best_score_,\n",
    "        'best_std_auc' :  grid_search.cv_results_['std_test_AUC'][best_index],\n",
    "        'best_sensitivity': best_sensitivity,\n",
    "        'best_std_sensitivity': best_std_sensitivity,\n",
    "        'best_specificity': best_specificity,\n",
    "        'best_std_specificity': best_std_specificity,\n",
    "        'best_accuracy': best_accuracy,\n",
    "        'best_std_accuracy': best_std_accuracy,\n",
    "        '#features': k,\n",
    "        'features': selected_features\n",
    "        })\n",
    "        print('auc: ', grid_search.best_score_)\n",
    "\n",
    "# Find the best classifier based on accuracy\n",
    "best_result = max(results, key=lambda x: x['best_auc'])\n",
    "best = f\"Best Classifier: {best_result['classifier']} \\n\" + f\"Number of features: {best_result['#features']}\\n\" + \"Features:\" + str(best_result['features']) +\"\\n\" + \\\n",
    "f\"Best Params: {best_result['best_params']}\" +\"\\n\" + f\"Best AUC: {best_result['best_auc']:.4f}\" +\"\\n\" + f\"Best Sens: {best_result['best_sensitivity']:.4f}\" +\"\\n\"+ \\\n",
    "f\"Best Spec: {best_result['best_specificity']:.4f}\" + \"\\n\"  + f\"Best Accuracy: {best_result['best_accuracy']:.4f}\" + \"\\n\"\n",
    "\n",
    "\n",
    "# Create the LaTeX table as a string\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[htbp]\n",
    "\\\\centering\n",
    "\\\\caption{{Best Classifier Performance and Selected Features}}\n",
    "\\\\begin{{tabular}}{{|l|l|}}\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Classifier}} & {best_result['classifier']} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Classifier Parameters}} & {best_result['best_params']} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Number of Features}} & {best_result['#features']} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Feature List}} & {', '.join(best_result['features'])} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best AUC}} & {best_result['best_auc']:.2f} $\\\\pm$ {best_result['best_std_auc']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Sensitivity}} & {best_result['best_sensitivity']:.2f} $\\\\pm$ {best_result['best_std_sensitivity']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Specificity}} & {best_result['best_specificity']:.2f} $\\\\pm$ {best_result['best_std_specificity']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Accuracy}} & {best_result['best_accuracy']:.2f} $\\\\pm$ {best_result['best_std_accuracy']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\label{{tab:best_classifier}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "print(best)\n",
    "#print(latex_table)\n",
    "\n",
    "with open(f'{tw}tw_smote.txt', 'w') as f:\n",
    "    f.write(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "AUC: 0.43956043956043966 \n",
      " Sensitivity: 0.07692307692307693 \n",
      " Specificity: 0.5714285714285714 \n",
      " Accuracy: 0.25 \n",
      "\n",
      "3\n",
      "AUC: 0.34375 \n",
      " Sensitivity: 0.0625 \n",
      " Specificity: 0.75 \n",
      " Accuracy: 0.2 \n",
      "\n",
      "4\n",
      "AUC: 0.4166666666666667 \n",
      " Sensitivity: 0.7777777777777778 \n",
      " Specificity: 0.0 \n",
      " Accuracy: 0.7 \n",
      "\n",
      "5\n",
      "AUC: 0.15789473684210525 \n",
      " Sensitivity: 0.9473684210526315 \n",
      " Specificity: 0.0 \n",
      " Accuracy: 0.9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the best models in the Coimbra'a Cohort\n",
    "for k in range(2,6):\n",
    "    print(k)\n",
    "    train_set = pd.read_csv('../data/lisbon/conversion_ad/{}tw_no_norm.csv'.format(k))\n",
    "    y_train = train_set['Evolution'].copy()\n",
    "\n",
    "    #train_set, test_set, y_train, y_test = train_test_split(train_set, y_train, test_size=0.20, random_state=42, stratify=y_train)\n",
    "    test_set = pd.read_csv('../data/coimbra/conversion_ad/{}tw_no_norm.csv'.format(k))\n",
    "    y_test = test_set['Evolution'].copy()\n",
    "\n",
    "    if k == 2:\n",
    "        clf = SVC(C=10, kernel = 'poly', probability = True, random_state = 42)\n",
    "        features = ['COCA1', 'TPP1', 'HPT', 'CBLN1', 'ACYP2', 'GDIA', 'DHPR', 'HBB', 'TIMP2', 'SGCE', 'NPTXR', 'SODM', 'AFAM']\n",
    "    elif k == 3:\n",
    "        clf = XGBClassifier(learning_rate = 0.01, max_depth =5, n_estimators = 50, objective = 'binary:logistic', random_state = 42)\n",
    "        features = ['HBB', 'HRG', 'IBP6', 'ACYP2']\n",
    "    elif k == 4:\n",
    "        clf =GaussianNB(var_smoothing=10**-9)\n",
    "        features = ['RELN', 'CNTN2', 'CLC11', 'NRP2', 'CNTP4', 'APOL1', 'EPDR1', 'TAGL', 'APOA1', 'TRFE', 'HPT', 'EGFLA', 'CSPG2', 'CIP4', 'EFNB3', 'idade', 'GRIA4', 'NRX1A', 'LFNG', 'ACTS', 'CBLN4', 'NEUS']\n",
    "    elif k == 5:\n",
    "        clf =RandomForestClassifier(n_estimators= 10, random_state=42)\n",
    "        features = ['APOL1', 'NRP2', 'CIP4', 'TRFE', 'RELN', 'CLC11', 'SORL', 'APOA1', 'HPT', 'C163A', 'GRIA4', 'APLP2', \n",
    "                    'PRELP', 'FGFR2', 'CBLN4', 'IGA2', 'PLXB2', 'TAGL', 'CNTN6', 'IBP6', 'SPON1', 'SAP', 'MMSE', 'SAA4', 'NPC2',\n",
    "                    'ALBU', 'FRIL', 'CNTN2', 'SGCE', 'EFNB3', 'C1RL', 'CNTP4', 'EGFLA', 'MYO6', 'EPDR1', 'VGF', 'idade', 'CAHD1', \n",
    "                    'NRX1A', 'PTPRF', 'MANBA', 'NEUS', 'RTN4R', 'A2AP', 'NAR3', 'TIMP2', 'KLKB1', 'AMBP', 'DHPR', 'KV127', 'TPP1', \n",
    "                    'NEO1', 'CPVL', 'B4GA1', 'COMP', 'HBA', 'LFNG', 'APLP1', 'ALS', 'OMD', 'CSPG2', 'NPTXR', 'A1AG1', 'NID2', 'NCAN', \n",
    "                    'FUCO2', 'KPYM', 'ROBO1', 'PEDF', 'FETUA', 'MA1C1', 'AEBP1', 'FGFR1', 'AFAM', 'CFAI', 'HRG', 'SAP3', 'ANT3', 'FHR1', \n",
    "                    'PGS2', 'FUCO', 'HEMO', 'SODM', 'CADH2', 'COCA1', 'IGK', 'FBLN2', 'TTHY', 'LTBP1', 'NBL1', 'KV106', 'LDHB', 'HV349',\n",
    "                    'ACTS', 'CBPQ', 'PEBP1', 'LV657', 'APOB', 'KV37', 'C4BPA', 'LTBP4', 'CFAB', 'FIBG', 'ITIH4', 'CSFdataabeta42', 'CO4B', \n",
    "                    'APOA4', 'C1QA', 'RNAS4', 'COFA1', 'CO9', 'PPIC', 'DKK3', 'ICAM5', 'SLIK1', 'CNTP2', 'CERU', 'CSFdatatTau', 'PON1', 'CO6A2',\n",
    "                    'VWF', 'H6ST3', 'GDIA', 'CBLN1', 'PTPRZ', 'A1BG', 'ITIH1', 'HV118', 'KNG1', 'C1QT3', 'HEXB', 'LV310', 'NID1', 'A1AG2', \n",
    "                    'CSFdatapTau', 'PCDC2', 'C1QT1', 'SLIK4', 'FSTL5', 'SPRL1', 'A2GL', 'ICOSL', 'CO6', 'ZA2G', 'HBB', 'LV39',\n",
    "                    'CBPB2', 'ENDD1', 'DCC', 'KCC2A', 'C1QC', 'CBG', 'MDHC', 'ACYP2']\n",
    "\n",
    "    train_set = train_set[features]\n",
    "    test_set = test_set[features]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    train_set = scaler.fit_transform(train_set)\n",
    "    test_set = scaler.transform(test_set)\n",
    "\n",
    "    smote = SMOTE(k_neighbors=3, sampling_strategy=0.8, random_state = 42)\n",
    "    train_set, y_train = smote.fit_resample(train_set, y_train)\n",
    "\n",
    "    clf.fit(train_set, y_train)\n",
    "    y_pred = clf.predict(test_set)\n",
    "    auc = roc_auc_score(y_test, clf.predict_proba(test_set)[:,1])\n",
    "    sensitivity = sens(y_test, y_pred)\n",
    "    specificity = spec(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results_str = f'AUC: {auc} \\n Sensitivity: {sensitivity} \\n Specificity: {specificity} \\n Accuracy: {accuracy} \\n'\n",
    "    print(results_str)\n",
    "    latex_table = f\"\"\"\n",
    "        \\\\begin{{table}}[htbp]\n",
    "        \\\\centering\n",
    "        \\\\caption{{Best Classifier Performance and Selected Features {k}tw}}\n",
    "        \\\\begin{{tabular}}{{|l|l|}}\n",
    "        \\\\hline\n",
    "        \\\\textbf{{AUC}} & {auc:.2f}\\\\\n",
    "        \\\\hline\n",
    "        \\\\textbf{{Sensitivity}} & {sensitivity:.2f} \\\\\n",
    "        \\\\hline\n",
    "        \\\\textbf{{Specificity}} & {specificity:.2f} \\\\\n",
    "        \\\\hline\n",
    "        \\\\textbf{{Accuracy}} & {accuracy:.2f} \\\\\n",
    "        \\\\hline\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\label{{tab:best_classifier}}\n",
    "        \\\\end{{table}}\n",
    "        \"\"\"\n",
    "    with open(f'{k}tw_smote_coimbra_test.txt', 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tw 4\n",
    "\n",
    "Best Classifier: SVC\n",
    "\n",
    "Number of features: 24\n",
    "\n",
    "Features:  ['RELN', 'NPTXR', 'CLC11', 'CNTN2', 'NRP2', 'EPDR1', 'CBLN4', 'CNTP4', 'idade', 'EFNB3', 'APOL1', 'TAGL', 'GRIA4', 'LFNG', 'NRX1A', 'ITIH1', 'CADH2', 'CSPG2', 'PEBP1', 'PLXB2', 'HRG', 'CIP4', 'LV657', 'NEUS']\n",
    "\n",
    "Best Params: {'classification__C': 1, 'classification__kernel': 'rbf', 'classification__probability': True}\n",
    "\n",
    "Best AUC: 0.7517\n",
    "\n",
    "Best Sens: 0.9300\n",
    "\n",
    "Best Spec: 0.1900\n",
    "\n",
    "Best Accuracy: 0.7000\n",
    "\n",
    "\n",
    "SMOTE: Best Classifier: SVC\n",
    "Number of features: 49\n",
    "Features:['CLC11', 'NPTXR', 'RELN', 'CNTP4', 'CNTN2', 'LFNG', 'CBLN4', 'EFNB3', 'HRG', 'PEBP1', 'CIP4', 'APOL1', 'NRP2', 'PLXB2', 'LV657', 'TAGL', 'HPT', 'GRIA4', 'HBB', 'CSPG2', 'FGFR2', 'SLIK1', 'idade', 'EGFLA', 'KCC2A', 'OMD', 'MYO6', 'COMP', 'PGS2', 'CADH2', 'EPDR1', 'HBA', 'SODM', 'NRX1A', 'NEUS', 'CBG', 'ROBO1', 'ITIH1', 'IGA2', 'SCG1', 'KV37', 'APOB', 'CSFdataabeta42', 'MMSE', 'ANT3', 'ENDD1', 'A1AG1', 'TPP1', 'VWF']\n",
    "Best Params: {'classification__C': 10, 'classification__kernel': 'linear', 'classification__probability': True}\n",
    "Best AUC: 0.7367\n",
    "Best Sens: 0.7867\n",
    "Best Spec: 0.4400\n",
    "Best Accuracy: 0.6767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
