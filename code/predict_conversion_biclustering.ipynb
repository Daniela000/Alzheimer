{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV, LeaveOneOut\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn import tree\n",
    "from sklearn.cluster import SpectralBiclustering\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(5000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"bic_prediction.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_13476\\1882002347.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_features['sexo'].replace({'M' : 0, 'F': 1}, inplace = True)\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_13476\\1882002347.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all_features['sexo'].replace({'M' : 0, 'F': 1}, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>sexo</th>\n",
       "      <th>CSFdatatTau</th>\n",
       "      <th>CSFdatapTau</th>\n",
       "      <th>CSFdataabeta42</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>NRP2</th>\n",
       "      <th>APOA1</th>\n",
       "      <th>FETUA</th>\n",
       "      <th>A1AG1</th>\n",
       "      <th>...</th>\n",
       "      <th>B4GA1</th>\n",
       "      <th>KV127</th>\n",
       "      <th>NAR3</th>\n",
       "      <th>MYO6</th>\n",
       "      <th>MANBA</th>\n",
       "      <th>SODM</th>\n",
       "      <th>FIBG</th>\n",
       "      <th>CNTP4</th>\n",
       "      <th>HV349</th>\n",
       "      <th>A2AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>95</td>\n",
       "      <td>552</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00184</td>\n",
       "      <td>9.050000e-06</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>563</td>\n",
       "      <td>77</td>\n",
       "      <td>349</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00434</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>1.460000e-06</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1201</td>\n",
       "      <td>135</td>\n",
       "      <td>399</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>6.540000e-06</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>104</td>\n",
       "      <td>389</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.00514</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>2.540000e-05</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.00230</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>26</td>\n",
       "      <td>324</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.00313</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>7.520000e-07</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>74</td>\n",
       "      <td>504</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>3.090000e-06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>404</td>\n",
       "      <td>68</td>\n",
       "      <td>855</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.00487</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00229</td>\n",
       "      <td>9.840000e-06</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>770</td>\n",
       "      <td>103</td>\n",
       "      <td>540</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>1.400000e-06</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00243</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>110</td>\n",
       "      <td>475</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00443</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>1.010000e-05</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.00235</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>86</td>\n",
       "      <td>558</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>8.910000e-06</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.00231</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>892</td>\n",
       "      <td>117</td>\n",
       "      <td>512</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>1.960000e-05</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>767</td>\n",
       "      <td>100</td>\n",
       "      <td>513</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>2.780000e-06</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1830</td>\n",
       "      <td>165</td>\n",
       "      <td>440</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.00361</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>8.910000e-06</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>767</td>\n",
       "      <td>73</td>\n",
       "      <td>389</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.00359</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>1.810000e-05</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>61</td>\n",
       "      <td>473</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00287</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>4.580000e-06</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.00209</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "      <td>91</td>\n",
       "      <td>580</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>1.140000e-05</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>43</td>\n",
       "      <td>587</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.00216</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>2.620000e-06</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>35</td>\n",
       "      <td>406</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>4.040000e-06</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1150</td>\n",
       "      <td>123</td>\n",
       "      <td>421</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00294</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00342</td>\n",
       "      <td>2.380000e-06</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>65</td>\n",
       "      <td>487</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>2.480000e-05</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1850</td>\n",
       "      <td>133</td>\n",
       "      <td>381</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00444</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00379</td>\n",
       "      <td>3.270000e-06</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>576</td>\n",
       "      <td>60</td>\n",
       "      <td>571</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.00359</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>9.910000e-06</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>70</td>\n",
       "      <td>555</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>2.460000e-05</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>603</td>\n",
       "      <td>63</td>\n",
       "      <td>560</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.00480</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>3.300000e-06</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.00252</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.001490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1360</td>\n",
       "      <td>118</td>\n",
       "      <td>609</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.00575</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>4.240000e-06</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1130</td>\n",
       "      <td>111</td>\n",
       "      <td>479</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>1.360000e-05</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>75</td>\n",
       "      <td>525</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00294</td>\n",
       "      <td>2.100000e-05</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00326</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>498</td>\n",
       "      <td>66</td>\n",
       "      <td>465</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.00602</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>1.900000e-05</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.00229</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1790</td>\n",
       "      <td>136</td>\n",
       "      <td>652</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.00443</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00304</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.00360</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>44</td>\n",
       "      <td>375</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>5.790000e-06</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>749</td>\n",
       "      <td>98</td>\n",
       "      <td>580</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.00315</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>1.440000e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.00154</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "      <td>140</td>\n",
       "      <td>450</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>2.400000e-05</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "      <td>75</td>\n",
       "      <td>555</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00286</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>8.890000e-06</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00457</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>59</td>\n",
       "      <td>494</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00363</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00168</td>\n",
       "      <td>7.700000e-06</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.00269</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>30</td>\n",
       "      <td>463</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.00383</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>1.310000e-05</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>929</td>\n",
       "      <td>108</td>\n",
       "      <td>596</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.00314</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00247</td>\n",
       "      <td>3.440000e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    idade  sexo  CSFdatatTau  CSFdatapTau  CSFdataabeta42  MMSE      NRP2  \\\n",
       "0      76     1          618           95             552    27  0.000155   \n",
       "1      77     0          563           77             349    30  0.000020   \n",
       "2      72     0         1201          135             399    22  0.000031   \n",
       "3      61     1          680          104             389    26  0.000145   \n",
       "4      63     1          200           26             324    22  0.000012   \n",
       "5      59     1          540           74             504    24  0.000032   \n",
       "6      74     1          404           68             855    23  0.000019   \n",
       "7      73     0          770          103             540    23  0.000020   \n",
       "8      61     1         1080          110             475    25  0.000013   \n",
       "9      71     0          702           86             558    26  0.000013   \n",
       "10     67     1          892          117             512    21  0.000158   \n",
       "11     66     1          767          100             513    25  0.000033   \n",
       "12     67     1         1830          165             440    21  0.000173   \n",
       "13     68     1          767           73             389    26  0.000016   \n",
       "14     65     1          520           61             473    25  0.000025   \n",
       "15     71     0          869           91             580    26  0.000017   \n",
       "16     70     0          329           43             587    25  0.000012   \n",
       "17     66     1          333           35             406    27  0.000090   \n",
       "18     67     1         1150          123             421    21  0.000013   \n",
       "19     73     0          519           65             487    25  0.000098   \n",
       "20     68     1         1850          133             381    30  0.000025   \n",
       "21     59     1          576           60             571    24  0.000070   \n",
       "22     65     0          606           70             555    28  0.000015   \n",
       "23     62     1          603           63             560    24  0.000008   \n",
       "24     77     1         1360          118             609    24  0.000028   \n",
       "25     72     1         1130          111             479    22  0.000227   \n",
       "26     79     1          594           75             525    26  0.000170   \n",
       "27     75     1          498           66             465    25  0.000162   \n",
       "28     65     1         1790          136             652    25  0.000198   \n",
       "29     71     0          277           44             375    28  0.000293   \n",
       "30     69     1          749           98             580    25  0.000067   \n",
       "31     58     0         1100          140             450    28  0.000015   \n",
       "32     74     1          566           75             555    27  0.000025   \n",
       "33     71     0          539           59             494    24  0.000031   \n",
       "34     73     0          186           30             463    26  0.000063   \n",
       "35     64     1          929          108             596    25  0.000006   \n",
       "\n",
       "      APOA1     FETUA     A1AG1  ...    B4GA1         KV127      NAR3  \\\n",
       "0   0.00331  0.000652  0.000652  ...  0.00184  9.050000e-06  0.000070   \n",
       "1   0.00434  0.000902  0.000974  ...  0.00201  1.460000e-06  0.000161   \n",
       "2   0.00223  0.000419  0.000876  ...  0.00258  6.540000e-06  0.000165   \n",
       "3   0.00514  0.001170  0.001470  ...  0.00202  2.540000e-05  0.000173   \n",
       "4   0.00313  0.000769  0.001660  ...  0.00154  7.520000e-07  0.000116   \n",
       "5   0.00370  0.000844  0.000875  ...  0.00223  3.090000e-06  0.000169   \n",
       "6   0.00487  0.001050  0.001100  ...  0.00229  9.840000e-06  0.000239   \n",
       "7   0.00445  0.001070  0.001710  ...  0.00146  1.400000e-06  0.000107   \n",
       "8   0.00443  0.000885  0.001610  ...  0.00125  1.010000e-05  0.000091   \n",
       "9   0.00451  0.000796  0.001170  ...  0.00193  8.910000e-06  0.000169   \n",
       "10  0.00558  0.000906  0.001630  ...  0.00390  1.960000e-05  0.000188   \n",
       "11  0.00269  0.000199  0.001000  ...  0.00369  2.780000e-06  0.000184   \n",
       "12  0.00361  0.000736  0.001170  ...  0.00282  8.910000e-06  0.000179   \n",
       "13  0.00359  0.000221  0.002170  ...  0.00196  1.810000e-05  0.000112   \n",
       "14  0.00287  0.000941  0.001390  ...  0.00246  4.580000e-06  0.000116   \n",
       "15  0.00338  0.000649  0.000897  ...  0.00274  1.140000e-05  0.000184   \n",
       "16  0.00216  0.000796  0.000617  ...  0.00238  2.620000e-06  0.000091   \n",
       "17  0.00372  0.000943  0.001570  ...  0.00132  4.040000e-06  0.000116   \n",
       "18  0.00294  0.000513  0.000863  ...  0.00342  2.380000e-06  0.000197   \n",
       "19  0.00456  0.001310  0.001050  ...  0.00196  2.480000e-05  0.000252   \n",
       "20  0.00444  0.000747  0.000939  ...  0.00379  3.270000e-06  0.000168   \n",
       "21  0.00359  0.000982  0.001080  ...  0.00155  9.910000e-06  0.000148   \n",
       "22  0.00590  0.001050  0.001400  ...  0.00192  2.460000e-05  0.000209   \n",
       "23  0.00480  0.000946  0.001330  ...  0.00338  3.300000e-06  0.000149   \n",
       "24  0.00575  0.000901  0.001180  ...  0.00330  4.240000e-06  0.000164   \n",
       "25  0.00428  0.000746  0.001310  ...  0.00240  1.360000e-05  0.000088   \n",
       "26  0.00525  0.000811  0.001730  ...  0.00294  2.100000e-05  0.000131   \n",
       "27  0.00602  0.000707  0.000653  ...  0.00272  1.900000e-05  0.000136   \n",
       "28  0.00443  0.000810  0.000865  ...  0.00304  5.500000e-06  0.000226   \n",
       "29  0.00611  0.001460  0.001970  ...  0.00206  5.790000e-06  0.000303   \n",
       "30  0.00315  0.000607  0.000982  ...  0.00227  1.440000e-06  0.000104   \n",
       "31  0.00461  0.000810  0.000879  ...  0.00192  2.400000e-05  0.000087   \n",
       "32  0.00286  0.000854  0.001010  ...  0.00323  8.890000e-06  0.000135   \n",
       "33  0.00363  0.000716  0.001420  ...  0.00168  7.700000e-06  0.000146   \n",
       "34  0.00383  0.000839  0.002030  ...  0.00150  1.310000e-05  0.000169   \n",
       "35  0.00314  0.000128  0.001590  ...  0.00247  3.440000e-06  0.000104   \n",
       "\n",
       "        MYO6     MANBA      SODM     FIBG     CNTP4     HV349      A2AP  \n",
       "0   0.000059  0.000210  0.000079  0.00122  0.000135  0.000127  0.000954  \n",
       "1   0.000034  0.001250  0.000043  0.00257  0.000411  0.000096  0.000550  \n",
       "2   0.000037  0.000333  0.000297  0.00173  0.000242  0.000077  0.000539  \n",
       "3   0.000049  0.001120  0.000084  0.00230  0.000868  0.000151  0.000663  \n",
       "4   0.000372  0.000826  0.000284  0.00124  0.000973  0.000117  0.000697  \n",
       "5   0.000052  0.000279  0.000098  0.00143  0.000432  0.000141  0.000695  \n",
       "6   0.000029  0.000466  0.000074  0.00277  0.000298  0.000100  0.001120  \n",
       "7   0.000049  0.000207  0.000076  0.00243  0.000317  0.000160  0.001130  \n",
       "8   0.000029  0.000761  0.000053  0.00235  0.000205  0.000158  0.000899  \n",
       "9   0.000038  0.000262  0.000070  0.00231  0.000928  0.000099  0.000514  \n",
       "10  0.000093  0.000171  0.000124  0.00268  0.000364  0.000115  0.000818  \n",
       "11  0.000046  0.000812  0.000076  0.00192  0.000320  0.000019  0.000901  \n",
       "12  0.000077  0.000172  0.000096  0.00267  0.000344  0.000160  0.000484  \n",
       "13  0.000029  0.001000  0.000092  0.00214  0.000179  0.000074  0.001030  \n",
       "14  0.000420  0.000419  0.000081  0.00209  0.000407  0.000106  0.001410  \n",
       "15  0.000048  0.000406  0.000066  0.00174  0.000249  0.000107  0.000608  \n",
       "16  0.000034  0.000237  0.000286  0.00167  0.000963  0.000126  0.000998  \n",
       "17  0.000272  0.000427  0.000125  0.00202  0.000530  0.000107  0.001140  \n",
       "18  0.000041  0.001320  0.000107  0.00154  0.000217  0.000051  0.000775  \n",
       "19  0.000022  0.000679  0.000025  0.00261  0.000964  0.000146  0.000694  \n",
       "20  0.000043  0.000791  0.000088  0.00248  0.000328  0.000100  0.000547  \n",
       "21  0.000267  0.000466  0.000279  0.00186  0.000280  0.000120  0.000639  \n",
       "22  0.000028  0.001190  0.000093  0.00295  0.000292  0.000257  0.001140  \n",
       "23  0.000035  0.001430  0.000086  0.00252  0.000398  0.000096  0.001490  \n",
       "24  0.000352  0.000521  0.000113  0.00281  0.000216  0.000122  0.000892  \n",
       "25  0.000028  0.000398  0.000020  0.00263  0.000221  0.000087  0.000504  \n",
       "26  0.000028  0.000213  0.000067  0.00326  0.000223  0.000135  0.000933  \n",
       "27  0.000027  0.000892  0.000262  0.00229  0.000178  0.000041  0.000470  \n",
       "28  0.000040  0.000476  0.000119  0.00360  0.000303  0.000085  0.000404  \n",
       "29  0.000063  0.000361  0.000214  0.00239  0.000273  0.000131  0.000883  \n",
       "30  0.000020  0.000828  0.000169  0.00154  0.000125  0.000045  0.000949  \n",
       "31  0.000021  0.000487  0.000036  0.00238  0.000183  0.000166  0.000978  \n",
       "32  0.000473  0.000508  0.000031  0.00457  0.000250  0.000141  0.001140  \n",
       "33  0.000019  0.000987  0.000016  0.00269  0.000246  0.000093  0.001050  \n",
       "34  0.000406  0.000756  0.000234  0.00372  0.001020  0.000117  0.001230  \n",
       "35  0.000339  0.000424  0.000083  0.00268  0.000411  0.000111  0.000385  \n",
       "\n",
       "[36 rows x 170 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = 2\n",
    "dir ='lisbon'\n",
    "df = pd.read_csv('../data/'+dir+'/conversion_ad/{}tw_no_norm.csv'.format(tw))\n",
    "all_features = df.copy()\n",
    "y = df['Evolution'].copy()\n",
    "all_features.drop(columns = ['Code','Group', 'BBA', 'CSFdate', 'comentarios', 'Conversion', 'data', 'tempofollowup', 'Evolution', 'Cluster'], inplace = True) # drop unwanted columns\n",
    "all_features['sexo'].replace({'M' : 0, 'F': 1}, inplace = True)\n",
    "numerical_features = [feature for feature in all_features.columns if feature not in ['sexo']]\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers to evaluate\n",
    "# Define classifiers and their parameter grids\n",
    "classifiers = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(solver='liblinear'),\n",
    "        'params': {\n",
    "            'classification__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classification__class_weight' : [None, 'balanced'],\n",
    "            'classification__penalty': ['l1', 'l2'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'classification__n_estimators': [10,50, 100, 200],\n",
    "            'classification__max_depth': [None, 10, 15,20],\n",
    "            'classification__max_features' : ['sqrt', 'log2',None],\n",
    "            'classification__class_weight' : [None, 'balanced'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'XGBgClassifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'classification__n_estimators': [10, 50, 100,300],\n",
    "            'classification__max_depth': [5,10,20,30],\n",
    "            'classification__learning_rate': [0.0001, 0.001, 0.01, 0.1,1],\n",
    "            'classification__objective': ['binary:logistic'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'classification__C': [0.1, 1, 10, 5],\n",
    "            'classification__kernel': ['linear','poly','rbf', 'sigmoid'],\n",
    "            'classification__probability': [True],\n",
    "            'classification__class_weight' : [None, 'balanced'], 'classification__random_state' : [42]\n",
    "        }\n",
    "    },\n",
    "    'NB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {'classification__var_smoothing' : [10**-9, 10**-8, 10**-10]}\n",
    "    },\n",
    "    'DTClassifier': {\n",
    "    'model': tree.DecisionTreeClassifier(),\n",
    "    'params': {'classification__max_depth': [None, 10, 20],\n",
    "              'classification__class_weight' : [None, 'balanced'],\n",
    "              'classification__random_state' : [42]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_scorer.py:548: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "\n",
    "def sens(y_true, y_pred): return tp(y_true, y_pred) / \\\n",
    "    (fn(y_true, y_pred) + tp(y_true, y_pred))\n",
    "\n",
    "\n",
    "def spec(y_true, y_pred): return tn(y_true, y_pred) / \\\n",
    "    (fp(y_true, y_pred) + tn(y_true, y_pred))\n",
    "\n",
    "sensitivity_scorer = make_scorer(sens)\n",
    "\n",
    "# Specificity scorer\n",
    "specificity_scorer = make_scorer(spec)\n",
    "\n",
    "# AUC scorer\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "# accuracy scorer\n",
    "accuracy_scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Biclustering(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, n_clusters = 3, method = 'bistochastic',svd_method = 'randomized', random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.method = method\n",
    "        self.svd_method = svd_method\n",
    "        self.random_state = random_state\n",
    "        self.biclusters = []\n",
    "    def fit(self, X, y):\n",
    "        print('ola')\n",
    "        # Clear biclusters to prevent accumulation\n",
    "        self.biclusters = []\n",
    "        self.x_train = X\n",
    "        self.biclustering = SpectralBiclustering(\n",
    "            n_clusters=self.n_clusters, \n",
    "            method=self.method, \n",
    "            svd_method=self.svd_method, \n",
    "            random_state=self.random_state)\n",
    "        \n",
    "        #biclusters of the positive class\n",
    "        print(y)\n",
    "        positive_indices = [i for i, val in enumerate(y) if val > 0]\n",
    "        print(positive_indices)\n",
    "        print(X.loc[positive_indices, :])\n",
    "        self.biclustering.fit(X.loc[positive_indices, :])\n",
    "        positive_biclusters = self.post_processing_bicluster(X[positive_indices, :])\n",
    "        positive_biclusters = self.filter_trivial(positive_biclusters)\n",
    "\n",
    "        # biclusters of the negative class\n",
    "        negative_indices = [i for i, val in enumerate(y) if val == 0]\n",
    "        self.biclustering.fit(X.loc[negative_indices, :])\n",
    "        negative_indices = self.post_processing_bicluster(X[negative_indices, :])\n",
    "        negative_indices = self.filter_trivial(negative_indices)\n",
    "        # concat biclusters\n",
    "        self.biclusters = positive_biclusters + negative_indices\n",
    "        print(self.biclusters)\n",
    "        # Check if biclusters were created\n",
    "        if len(self.biclusters) == 0:\n",
    "            print(\"Warning: No biclusters were found.\")\n",
    "        else:\n",
    "            print(f\"Found {len(self.biclusters)} biclusters.\")\n",
    "        return self\n",
    "\n",
    "    def get_number_bics(self):\n",
    "        return len(self.biclusters)\n",
    "\n",
    "    def filter_trivial(self, biclusters):\n",
    "        print(biclusters)\n",
    "        return [bic for bic in biclusters if len(bic[0]) >= 2 and len(bic[1]) >= 2]\n",
    "        #print(self.biclusters)\n",
    "\n",
    "    def post_processing_bicluster(self,X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        # Extracting the biclusters\n",
    "        n_biclusters = max(list(self.biclustering.row_labels_) + list(self.biclustering.column_labels_)) + 1\n",
    "        rows = defaultdict(list)\n",
    "        cols = defaultdict(list)\n",
    "\n",
    "        row_labels = self.biclustering.row_labels_\n",
    "        col_labels = self.biclustering.column_labels_\n",
    "\n",
    "        for i, label in enumerate(row_labels):\n",
    "           rows[label].append(X.index[i])\n",
    "\n",
    "        for j, label in enumerate(col_labels):\n",
    "            cols[label].append(X.columns[j])\n",
    "        \n",
    "        # Build biclusters\n",
    "        return [[rows[i], cols[i]] for i in range(n_biclusters)]\n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "        \n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        # Initialize dictionary for distances\n",
    "\n",
    "        distance_matrix = []\n",
    "        if len(self.biclusters) == 0:\n",
    "            print('Warning: No biclusters found, returning zero matrix')\n",
    "            return np.zeros(((X.shape[0], 1)))\n",
    "        #col_name = []\n",
    "        for b in range(len(self.biclusters)):\n",
    "            P = self.x_train.loc[self.biclusters[b][0],self.biclusters[b][1]] #patterns in the train set\n",
    "            # Check if P is empty or has NaNs\n",
    "            if P.empty or P.isnull().values.any():\n",
    "                continue\n",
    "            y_labels = P.columns\n",
    "            P = P.mean(axis = 0)\n",
    "            if len(P) == 0:\n",
    "                continue\n",
    "            # Precompute row submatrix \n",
    "            X_submatrix = X.loc[:, y_labels]\n",
    "            # Make sure shapes match before subtraction\n",
    "            if X_submatrix.shape[1] != len(P):\n",
    "                continue  # Skip if shapes are incompatible\n",
    "            # Compute the distance for each row\n",
    "            diff = (X_submatrix - P) ** 2\n",
    "            distance_matrix.append(np.sqrt(diff.sum(axis=1)) / len(P))\n",
    "            #col_name.append('bic_' + str(b)) \n",
    "\n",
    "        if len(distance_matrix) == 0:\n",
    "            print(\"Warning: No valid distances computed, returning zero matrix\")\n",
    "            return np.zeros(((X.shape[0], 1)))\n",
    "        distance_matrix = np.array(distance_matrix).T\n",
    "        \n",
    "        if len(distance_matrix[1]) == 1: #if one feature\n",
    "            distance_matrix = distance_matrix.reshape(-1, 1)\n",
    "        #distance_matrix = pd.DataFrame(distance_matrix, index = col_name).T\n",
    "        \n",
    "        return distance_matrix\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X,y).transform(X)\n",
    "    \n",
    "    def get_biclusters(self):\n",
    "        # Initialize an empty list to store each bicluster's data as a row\n",
    "        bicluster_rows = []\n",
    "        \n",
    "        for b in range(len(self.biclusters)):\n",
    "            # Dictionary to hold data for the current bicluster\n",
    "            bicluster_data = {'ID': b, 'Pattern': [], 'n_samples': []}\n",
    "\n",
    "            # Loop through the features (columns) for this bicluster\n",
    "            for feature in self.biclusters[b][1]:\n",
    "                # Get the data for the rows and current feature in the bicluster\n",
    "                feature_values = self.x_train.loc[self.biclusters[b][0], feature]\n",
    "                \n",
    "                # Calculate the min and max values\n",
    "                min_val = feature_values.min()\n",
    "                max_val = feature_values.max()\n",
    "                \n",
    "                # Append the pattern in the format 'feature = [min, max]'\n",
    "                bicluster_data['Pattern'].append(f'{feature} = [{min_val:.2f}, {max_val:.2f}]')\n",
    "            bicluster_data['n_samples'].append(len(feature_values))\n",
    "            # Append the bicluster data to the list of rows\n",
    "            bicluster_rows.append(bicluster_data)\n",
    "        \n",
    "        # Convert the list of bicluster data into a DataFrame\n",
    "        bicluster_table = pd.DataFrame(bicluster_rows)\n",
    "        \n",
    "        # Display the table\n",
    "        print(bicluster_table)\n",
    "        return bicluster_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Perform grid search with cross-validation\u001b[39;00m\n\u001b[0;32m     31\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, clf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m], cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m: auc_scorer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m: sensitivity_scorer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecificity\u001b[39m\u001b[38;5;124m'\u001b[39m: specificity_scorer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_scorer}, refit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Get the index of the best model (based on AUC score)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m best_index \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_index_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the cross-validation procedure (5-fold cross-validation with 10 repetitions)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "cv = LeaveOneOut()\n",
    "all_scores = []\n",
    "k_scores = []\n",
    "# List to store results\n",
    "results = []\n",
    "#print(all_features)\n",
    "set_config(transform_output=\"pandas\")\n",
    "# Define the ColumnTransformer to apply MinMaxScaler only to numerical columns\n",
    "#preprocessor = ColumnTransformer(\n",
    "#    transformers=[\n",
    "#        ('num', MinMaxScaler(), numerical_features),  # Custom scaler for numerical features\n",
    "#        ('cat', 'passthrough', ['sexo'])            # Pass categorical columns unchanged\n",
    "#    ], remainder='passthrough', verbose_feature_names_out=False, sparse_threshold=0)     #remainder='passthrough'  # Ensure other columns are passed through if not specified\n",
    "\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(name)\n",
    "    pipeline = ImbPipeline([#('scaler', preprocessor),\n",
    "                            ('biclustering', Biclustering()),\n",
    "                            ('classification', clf['model'])])\n",
    "    \n",
    "    bic_params = {'biclustering__n_clusters' : list(range(2,36)), \n",
    "                  'biclustering__method' : ['bistochastic', 'scale', 'log'],\n",
    "                  'biclustering__svd_method' : ['randomized', 'arpack']}\n",
    "    \n",
    "    clf['params'].update(bic_params)  \n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(pipeline, clf['params'], cv=cv, scoring={'AUC': auc_scorer, 'Sensitivity': sensitivity_scorer, 'Specificity': specificity_scorer, 'Accuracy': accuracy_scorer}, refit = 'AUC', n_jobs=-1)\n",
    "    grid_search.fit(all_features, y)\n",
    "    # Get the index of the best model (based on AUC score)\n",
    "    best_index = grid_search.best_index_\n",
    "     # Extract the sensitivity and specificity for the best model\n",
    "    best_sensitivity = grid_search.cv_results_['mean_test_Sensitivity'][best_index]\n",
    "    best_std_sensitivity = grid_search.cv_results_['std_test_Sensitivity'][best_index]\n",
    "    best_specificity = grid_search.cv_results_['mean_test_Specificity'][best_index]\n",
    "    best_std_specificity = grid_search.cv_results_['std_test_Specificity'][best_index]\n",
    "    best_accuracy = grid_search.cv_results_['mean_test_Accuracy'][best_index]\n",
    "    best_std_accuracy = grid_search.cv_results_['std_test_Accuracy'][best_index]\n",
    "    # Get the best estimator (pipeline) from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "   \n",
    "    # Store results\n",
    "    results.append({\n",
    "    'classifier': name,\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'best_auc': grid_search.best_score_,\n",
    "    'best_std_auc' :  grid_search.cv_results_['std_test_AUC'][best_index],\n",
    "    'best_sensitivity': best_sensitivity,\n",
    "    'best_std_sensitivity': best_std_sensitivity,\n",
    "    'best_specificity': best_specificity,\n",
    "    'best_std_specificity': best_std_specificity,\n",
    "    'best_accuracy': best_accuracy,\n",
    "    'best_std_accuracy': best_std_accuracy,\n",
    "    })\n",
    "    print('best_auc :',  grid_search.best_score_)\n",
    "\n",
    "# Find the best classifier based on accuracy\n",
    "best_result = max(results, key=lambda x: x['best_auc'])\n",
    "best = f\"Best Classifier: {best_result['classifier']} \\n\" + \\\n",
    "f\"Best Params: {best_result['best_params']}\" +\"\\n\" + f\"Best AUC: {best_result['best_auc']:.4f}\" +\"\\n\" + f\"Best Sens: {best_result['best_sensitivity']:.4f}\" +\"\\n\"+ \\\n",
    "f\"Best Spec: {best_result['best_specificity']:.4f}\" + \"\\n\"  + f\"Best Accuracy: {best_result['best_accuracy']:.4f}\" + \"\\n\"\n",
    "\n",
    "\n",
    "# Create the LaTeX table as a string\n",
    "latex_table = f\"\"\"\n",
    "\\\\begin{{table}}[htbp]\n",
    "\\\\centering\n",
    "\\\\caption{{Best Classifier Performance and Biclustering {tw}tw}}\n",
    "\\\\begin{{tabular}}{{|l|l|}}\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Classifier}} & {best_result['classifier']} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Classifier Parameters}} & {best_result['best_params']} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best AUC}} & {best_result['best_auc']:.2f} $\\\\pm$ {best_result['best_std_auc']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Sensitivity}} & {best_result['best_sensitivity']:.2f} $\\\\pm$ {best_result['best_std_sensitivity']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Specificity}} & {best_result['best_specificity']:.2f} $\\\\pm$ {best_result['best_std_specificity']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\textbf{{Best Accuracy}} & {best_result['best_accuracy']:.2f} $\\\\pm$ {best_result['best_std_accuracy']:.2f} \\\\\\\\\n",
    "\\\\hline\n",
    "\\\\end{{tabular}}\n",
    "\\\\label{{tab:best_classifier}}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "print(best)\n",
    "#print(latex_table)\n",
    "\n",
    "with open(f'{tw}tw_biclustering.txt', 'w') as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_set.loc[:, 'sexo'] = train_set['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test.loc[:, 'sexo'] = X_test['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 biclusters.\n",
      "    ID                                            Pattern n_samples\n",
      "0    0  [CSFdataabeta42 = [0.24, 0.50], SLIK4 = [0.09,...       [3]\n",
      "1    1  [HRG = [0.29, 1.00], CERU = [0.59, 1.00], FHR1...       [3]\n",
      "2    2  [ALS = [0.44, 0.45], SE6L1 = [0.67, 0.72], CO9...       [5]\n",
      "3    3  [ZA2G = [0.15, 0.15], LTBP1 = [1.00, 1.00], FS...       [2]\n",
      "4    4  [C1QT1 = [0.58, 0.60], TPP1 = [0.18, 0.19], C1...       [2]\n",
      "5    5  [OMD = [0.02, 0.53], SCG1 = [0.13, 0.27], MA1C...       [2]\n",
      "6    6  [PLXB2 = [0.04, 0.15], GRIA4 = [0.21, 1.00], P...       [2]\n",
      "7    7  [idade = [0.67, 0.67], MMSE = [0.11, 0.11], AP...       [2]\n",
      "8    8         [CLC11 = [0.06, 0.06], VWF = [0.04, 0.04]]       [2]\n",
      "9    9  [C1RL = [0.10, 0.27], FHR2 = [0.06, 0.10], CHR...       [2]\n",
      "10  10  [NEO1 = [0.18, 0.61], VGF = [0.11, 0.30], GLU2...       [3]\n",
      "AUC: 0.39560439560439564 \n",
      " Sensitivity: 0.0 \n",
      " Specificity: 1.0 \n",
      " Accuracy: 0.35 \n",
      "\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_set.loc[:, 'sexo'] = train_set['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test.loc[:, 'sexo'] = X_test['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 biclusters.\n",
      "    ID                                            Pattern n_samples\n",
      "0    0  [PLXB2 = [0.30, 1.00], ALS = [0.46, 1.00], PON...       [3]\n",
      "1    1  [ZA2G = [0.07, 0.18], CO6 = [0.07, 0.50], ACTS...       [2]\n",
      "2    2  [A1AG1 = [0.25, 0.26], ANT3 = [0.79, 0.80], OM...       [2]\n",
      "3    3  [LFNG = [0.06, 0.07], HBB = [0.31, 0.32], HBA ...       [2]\n",
      "4    4  [KCC2A = [0.18, 0.64], PEBP1 = [0.40, 0.68], P...       [4]\n",
      "5    5  [IBP7 = [0.66, 0.87], GLU2B = [0.38, 0.40], SA...       [2]\n",
      "6    6  [KV37 = [0.31, 0.54], A1BG = [0.64, 0.65], GDI...       [2]\n",
      "7    7  [sexo = [0.00, 1.00], GRIA4 = [0.08, 0.53], SP...       [4]\n",
      "8    8  [COCA1 = [0.00, 0.61], KLKB1 = [0.03, 0.49], C...       [4]\n",
      "9    9  [A2GL = [0.25, 0.53], NID1 = [0.26, 0.43], EGF...       [3]\n",
      "10  10  [APOA1 = [0.54, 0.78], APOA4 = [0.74, 1.00], A...       [2]\n",
      "AUC: 0.421875 \n",
      " Sensitivity: 0.3125 \n",
      " Specificity: 0.75 \n",
      " Accuracy: 0.4 \n",
      "\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_set.loc[:, 'sexo'] = train_set['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test.loc[:, 'sexo'] = X_test['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 biclusters.\n",
      "    ID                                            Pattern n_samples\n",
      "0    0  [NID1 = [0.44, 0.48], DCC = [0.05, 0.09], EFNB...       [2]\n",
      "1    1  [ANT3 = [0.78, 0.87], ICAM5 = [0.19, 0.61], KN...       [2]\n",
      "2    2  [LFNG = [0.08, 0.08], FSTL5 = [0.75, 0.79], FR...       [2]\n",
      "3    3  [ZA2G = [0.44, 0.44], LTBP1 = [0.35, 0.35], DH...       [2]\n",
      "4    4  [COMP = [0.16, 0.64], PLXB2 = [0.33, 0.43], AL...       [2]\n",
      "5    5  [MMSE = [0.44, 0.44], OMD = [0.16, 0.19], KV10...       [2]\n",
      "6    6  [APOA4 = [0.32, 0.45], TTHY = [0.19, 0.33], PG...       [2]\n",
      "7    7  [CSFdataabeta42 = [0.05, 0.07], EGFLA = [0.09,...       [2]\n",
      "8    8  [GRIA4 = [0.58, 0.88], C1QT1 = [0.35, 0.43], C...       [2]\n",
      "9    9  [CERU = [0.31, 0.62], HEMO = [0.21, 0.52], A1B...       [2]\n",
      "10  10  [FETUA = [0.43, 0.58], SORL = [0.13, 0.41], C1...       [2]\n",
      "AUC: 0.6111111111111112 \n",
      " Sensitivity: 1.0 \n",
      " Specificity: 0.0 \n",
      " Accuracy: 0.9 \n",
      "\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_set.loc[:, 'sexo'] = train_set['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test.loc[:, 'sexo'] = X_test['sexo'].replace({'M' : 0, 'F': 1})\n",
      "C:\\Users\\danis\\AppData\\Local\\Temp\\ipykernel_11916\\3977669426.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 biclusters.\n",
      "   ID                                            Pattern n_samples\n",
      "0   0  [ANT3 = [0.34, 0.40], CERU = [0.00, 0.63], CBP...       [5]\n",
      "1   1  [APOL1 = [0.08, 0.49], ZA2G = [0.16, 0.22], PL...       [3]\n",
      "2   2  [VGF = [0.20, 0.22], ACTS = [0.83, 0.84], DSG2...       [3]\n",
      "3   3  [idade = [0.05, 0.67], MMSE = [0.11, 0.44], NR...       [3]\n",
      "4   4  [KV106 = [0.24, 0.24], CBLN4 = [0.49, 0.49], F...       [2]\n",
      "5   5  [APOA4 = [0.74, 1.00], COCA1 = [0.34, 0.38], E...       [2]\n",
      "6   6  [IBP6 = [0.99, 1.00], MDHC = [0.76, 0.77], CBP...       [2]\n",
      "7   7        [CLC11 = [0.03, 0.35], ALBU = [0.43, 0.96]]       [4]\n",
      "8   8  [A2GL = [0.37, 1.00], SLIK4 = [0.33, 0.58], CA...       [2]\n",
      "AUC: 0.4473684210526315 \n",
      " Sensitivity: 0.8947368421052632 \n",
      " Specificity: 0.0 \n",
      " Accuracy: 0.85 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_config(transform_output=\"pandas\")\n",
    "for k in range(2,6):\n",
    "    print(k)\n",
    "    train_set = pd.read_csv('../data/lisbon/conversion_ad/{}tw_no_norm.csv'.format(k))\n",
    "    y_train = train_set['Evolution'].copy()\n",
    "    train_set.drop(columns = ['Code','Group', 'BBA', 'CSFdate', 'comentarios', 'Conversion', 'data', 'tempofollowup', 'Evolution', 'Cluster'], inplace = True) # drop unwanted columns\n",
    "    train_set.loc[:, 'sexo'] = train_set['sexo'].replace({'M' : 0, 'F': 1})\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(train_set, y_train, test_size=0.2, random_state=42)\n",
    "    X_train = train_set\t\n",
    "    test_set = pd.read_csv('../data/coimbra/conversion_ad/{}tw_no_norm.csv'.format(k))\n",
    "    y_test = test_set['Evolution'].copy()\n",
    "    X_test = test_set[train_set.columns]\n",
    "    X_test.loc[:, 'sexo'] = X_test['sexo'].replace({'M' : 0, 'F': 1})\n",
    "    numerical_features = [i for i in X_train.columns if i !='Sexo']\n",
    "\n",
    "    #test_set['sexo'].replace({'M' : 0, 'F': 1}, inplace = True)\n",
    "\n",
    "    if k == 2:\n",
    "        biclustering = Biclustering(method='bistochastic', n_clusters = 32, svd_method='arpack')\n",
    "        clf = RandomForestClassifier(class_weight=None, max_depth = None, max_features = 'log2', n_estimators = 50, random_state=42)\n",
    "        k_neighbors = 5\n",
    "    elif k == 3:\n",
    "        biclustering = Biclustering(method='bistochastic', n_clusters = 20, svd_method='randomized')\n",
    "        clf = XGBClassifier(learning_rate=1, max_depth = 5,n_estimators = 300, objective = 'binary:logistic', random_state=42)\n",
    "        k_neighbors = 5\n",
    "    elif k == 4: \n",
    "        biclustering = Biclustering(method='log', n_clusters = 33, svd_method='randomized')\n",
    "        clf = XGBClassifier(learning_rate=1, max_depth = 5,n_estimators = 50, objective = 'binary:logistic', random_state=42)\n",
    "        k_neighbors = 5\n",
    "    elif k == 5:\n",
    "        biclustering = Biclustering(method='log', n_clusters = 32, svd_method='arpack')\n",
    "        clf = RandomForestClassifier(class_weight=None, max_depth = 10, max_features = 'log2', n_estimators = 10, random_state=42)\n",
    "        k_neighbors = 3\n",
    "\n",
    "    smote = SMOTENC(k_neighbors=k_neighbors, sampling_strategy=0.8,categorical_encoder = OneHotEncoder(sparse_output = False), categorical_features = ['sexo'], random_state = 42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[numerical_features]= scaler.fit_transform(X_train[numerical_features])\n",
    "    X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "    X_train = biclustering.fit_transform(X_train)\n",
    "    X_test = biclustering.transform(X_test)\n",
    "    bicluster_table = biclustering.get_biclusters()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    sensitivity = sens(y_test, y_pred)\n",
    "    specificity = spec(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results_str = f'AUC: {auc} \\n Sensitivity: {sensitivity} \\n Specificity: {specificity} \\n Accuracy: {accuracy} \\n'\n",
    "    print(results_str)\n",
    "    latex_table = f\"\"\"\n",
    "        \\\\begin{{table}}[htbp]\n",
    "        \\\\centering\n",
    "        \\\\caption{{Best Classifier Performance and Biclustering {k}tw}}\n",
    "        \\\\begin{{tabular}}{{|l|l|}}\n",
    "        \\\\hline\n",
    "        \\\\textbf{{AUC}} & {auc:.2f}\\\\\\\\\n",
    "        \\\\hline\n",
    "        \\\\textbf{{Sensitivity}} & {sensitivity:.2f} \\\\\\\\\n",
    "        \\\\hline\n",
    "        \\\\textbf{{Specificity}} & {specificity:.2f} \\\\\\\\\n",
    "        \\\\hline\n",
    "        \\\\textbf{{Accuracy}} & {accuracy:.2f} \\\\\\\\\n",
    "        \\\\hline\n",
    "        \\\\end{{tabular}}\n",
    "        \\\\label{{tab:best_classifier}}\n",
    "        \\\\end{{table}}\n",
    "        \"\"\"\n",
    "    with open(f'{k}tw_biclustering_coimbra_test.txt', 'w') as f:\n",
    "        f.write(latex_table)\n",
    "    with open(f'{k}tw_biclusters.txt', 'w') as f:\n",
    "        f.write(bicluster_table.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
